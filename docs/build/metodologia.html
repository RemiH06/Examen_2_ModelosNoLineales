

<!DOCTYPE html>
<html class="writer-html5" lang="es" data-content_root="./">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Metodolog√≠a &mdash; Predicci√≥n NVDA</title>
      <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="_static/css/theme.css?v=e59714d7" />

  
      <script src="_static/jquery.js?v=5d32c60e"></script>
      <script src="_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="_static/documentation_options.js?v=36c4ab74"></script>
      <script src="_static/doctools.js?v=9bcbadda"></script>
      <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
      <script src="_static/translations.js?v=f85f4cfb"></script>
      <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="√çndice" href="genindex.html" />
    <link rel="search" title="B√∫squeda" href="search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="index.html" class="icon icon-home">
            Examen2
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Buscar documentos" aria-label="Buscar documentos" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <!-- Local TOC -->
              <div class="local-toc"><ul>
<li><a class="reference internal" href="#">Metodolog√≠a</a><ul>
<li><a class="reference internal" href="#pipeline-general-del-proyecto">Pipeline General del Proyecto</a></li>
<li><a class="reference internal" href="#modelo-1-sarimax">Modelo 1: SARIMAX</a><ul>
<li><a class="reference internal" href="#estructura-del-modelo">Estructura del Modelo</a></li>
<li><a class="reference internal" href="#ecuacion-general">Ecuaci√≥n General</a></li>
<li><a class="reference internal" href="#seleccion-de-ordenes">Selecci√≥n de √ìrdenes</a></li>
<li><a class="reference internal" href="#configuracion-final">Configuraci√≥n Final</a></li>
<li><a class="reference internal" href="#criterios-de-validacion">Criterios de Validaci√≥n</a></li>
</ul>
</li>
<li><a class="reference internal" href="#modelo-2-ffnn-feed-forward-neural-network">Modelo 2: FFNN (Feed-Forward Neural Network)</a><ul>
<li><a class="reference internal" href="#arquitectura-de-la-red">Arquitectura de la Red</a></li>
<li><a class="reference internal" href="#hiperparametros-seleccionados">Hiperpar√°metros Seleccionados</a></li>
<li><a class="reference internal" href="#funcion-de-activacion-relu">Funci√≥n de Activaci√≥n: ReLU</a></li>
<li><a class="reference internal" href="#regularizacion">Regularizaci√≥n</a></li>
<li><a class="reference internal" href="#optimizador-adam">Optimizador: Adam</a></li>
<li><a class="reference internal" href="#walk-forward-validation">Walk-Forward Validation</a></li>
<li><a class="reference internal" href="#early-stopping">Early Stopping</a></li>
</ul>
</li>
<li><a class="reference internal" href="#preprocesamiento-de-datos">Preprocesamiento de Datos</a><ul>
<li><a class="reference internal" href="#escalado-con-minmaxscaler">Escalado con MinMaxScaler</a></li>
<li><a class="reference internal" href="#division-de-datos">Divisi√≥n de Datos</a></li>
<li><a class="reference internal" href="#creacion-de-secuencias">Creaci√≥n de Secuencias</a></li>
</ul>
</li>
<li><a class="reference internal" href="#metricas-de-evaluacion">M√©tricas de Evaluaci√≥n</a><ul>
<li><a class="reference internal" href="#rmse-root-mean-squared-error">1. RMSE (Root Mean Squared Error)</a></li>
<li><a class="reference internal" href="#mae-mean-absolute-error">2. MAE (Mean Absolute Error)</a></li>
<li><a class="reference internal" href="#mape-mean-absolute-percentage-error">3. MAPE (Mean Absolute Percentage Error)</a></li>
<li><a class="reference internal" href="#criterios-de-exito">Criterios de √âxito</a></li>
</ul>
</li>
<li><a class="reference internal" href="#reproducibilidad">Reproducibilidad</a><ul>
<li><a class="reference internal" href="#semilla-fija">Semilla Fija</a></li>
<li><a class="reference internal" href="#control-de-versiones">Control de Versiones</a></li>
<li><a class="reference internal" href="#entorno-de-ejecucion">Entorno de Ejecuci√≥n</a></li>
</ul>
</li>
<li><a class="reference internal" href="#limitaciones-y-consideraciones">Limitaciones y Consideraciones</a><ul>
<li><a class="reference internal" href="#limitaciones-del-proyecto">Limitaciones del Proyecto</a></li>
<li><a class="reference internal" href="#supuestos-del-modelo">Supuestos del Modelo</a></li>
<li><a class="reference internal" href="#consideraciones-eticas">Consideraciones √âticas</a></li>
</ul>
</li>
<li><a class="reference internal" href="#resumen-de-la-metodologia">Resumen de la Metodolog√≠a</a></li>
</ul>
</li>
</ul>
</div>
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">Examen2</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">Metodolog√≠a</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/metodologia.rst.txt" rel="nofollow"> Ver c√≥digo fuente de la p√°gina</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="metodologia">
<h1>Metodolog√≠a<a class="headerlink" href="#metodologia" title="Link to this heading">ÔÉÅ</a></h1>
<p>Esta secci√≥n detalla la metodolog√≠a completa utilizada para construir y evaluar los modelos SARIMAX y FFNN.</p>
<section id="pipeline-general-del-proyecto">
<h2>Pipeline General del Proyecto<a class="headerlink" href="#pipeline-general-del-proyecto" title="Link to this heading">ÔÉÅ</a></h2>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>1. Descarga de datos (yfinance)
       ‚Üì
2. An√°lisis exploratorio (EDA)
       ‚Üì
3. Pruebas de estacionariedad
       ‚Üì
4. Preparaci√≥n de datos (train/test/future)
       ‚Üì
5. Entrenamiento de modelos
       ‚Üì
6. Evaluaci√≥n y comparaci√≥n
       ‚Üì
7. Predicciones finales (5 d√≠as)
</pre></div>
</div>
<p>‚Äî</p>
</section>
<section id="modelo-1-sarimax">
<h2>Modelo 1: SARIMAX<a class="headerlink" href="#modelo-1-sarimax" title="Link to this heading">ÔÉÅ</a></h2>
<p><strong>SARIMAX</strong> significa <em>Seasonal AutoRegressive Integrated Moving Average with eXogenous variables</em>.</p>
<section id="estructura-del-modelo">
<h3>Estructura del Modelo<a class="headerlink" href="#estructura-del-modelo" title="Link to this heading">ÔÉÅ</a></h3>
<p>Un modelo SARIMAX se define por dos conjuntos de √≥rdenes:</p>
<p><strong>Componente No Estacional: (p, d, q)</strong></p>
<ul class="simple">
<li><p><strong>p</strong>: Orden autoregresivo (AR) - n√∫mero de lags de la variable dependiente</p></li>
<li><p><strong>d</strong>: Grado de diferenciaci√≥n (I) - veces que se diferencia la serie</p></li>
<li><p><strong>q</strong>: Orden de media m√≥vil (MA) - n√∫mero de lags de los errores</p></li>
</ul>
<p><strong>Componente Estacional: (P, D, Q, s)</strong></p>
<ul class="simple">
<li><p><strong>P</strong>: Orden autoregresivo estacional</p></li>
<li><p><strong>D</strong>: Diferenciaci√≥n estacional</p></li>
<li><p><strong>Q</strong>: Media m√≥vil estacional</p></li>
<li><p><strong>s</strong>: Periodo estacional (e.g., 5 para d√≠as de la semana, 12 para meses)</p></li>
</ul>
</section>
<section id="ecuacion-general">
<h3>Ecuaci√≥n General<a class="headerlink" href="#ecuacion-general" title="Link to this heading">ÔÉÅ</a></h3>
<div class="math notranslate nohighlight">
\[\Phi_P(B^s)\phi_p(B)\nabla^D_s\nabla^d Y_t = \Theta_Q(B^s)\theta_q(B)\epsilon_t\]</div>
<p>Donde:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(Y_t\)</span>: Serie temporal en el tiempo t</p></li>
<li><p><span class="math notranslate nohighlight">\(B\)</span>: Operador de retardo (lag)</p></li>
<li><p><span class="math notranslate nohighlight">\(\nabla\)</span>: Operador de diferenciaci√≥n</p></li>
<li><p><span class="math notranslate nohighlight">\(\epsilon_t\)</span>: Error o ruido blanco</p></li>
</ul>
</section>
<section id="seleccion-de-ordenes">
<h3>Selecci√≥n de √ìrdenes<a class="headerlink" href="#seleccion-de-ordenes" title="Link to this heading">ÔÉÅ</a></h3>
<p>Para determinar los valores √≥ptimos de (p, d, q) y (P, D, Q, s):</p>
<ol class="arabic simple">
<li><p><strong>Diferenciaci√≥n (d)</strong></p>
<ul class="simple">
<li><p>Aplicar prueba ADF (Augmented Dickey-Fuller)</p></li>
<li><p>Si p-value &gt; 0.05 ‚Üí serie NO estacionaria ‚Üí aumentar d</p></li>
<li><p>Confirmar con prueba KPSS</p></li>
</ul>
</li>
<li><p><strong>√ìrdenes AR y MA (p, q)</strong></p>
<ul class="simple">
<li><p>Analizar gr√°ficas ACF (Autocorrelation Function)</p></li>
<li><p>Analizar gr√°ficas PACF (Partial Autocorrelation Function)</p></li>
<li><p>Reglas emp√≠ricas:</p>
<ul>
<li><p>Si ACF decae lentamente ‚Üí componente AR significativo</p></li>
<li><p>Si PACF corta en lag k ‚Üí p = k</p></li>
<li><p>Si ACF corta en lag k ‚Üí q = k</p></li>
</ul>
</li>
</ul>
</li>
<li><p><strong>Componente Estacional (P, D, Q, s)</strong></p>
<ul class="simple">
<li><p>Observar patrones repetitivos en ACF/PACF</p></li>
<li><p>Para acciones: s = 5 (semana burs√°til) o s = 21 (mes aproximado)</p></li>
</ul>
</li>
<li><p><strong>Criterios de Informaci√≥n</strong></p>
<ul class="simple">
<li><p><strong>AIC</strong> (Akaike Information Criterion): penaliza complejidad</p></li>
<li><p><strong>BIC</strong> (Bayesian Information Criterion): penaliza m√°s fuertemente</p></li>
<li><p>Menor AIC/BIC ‚Üí mejor modelo</p></li>
</ul>
</li>
</ol>
</section>
<section id="configuracion-final">
<h3>Configuraci√≥n Final<a class="headerlink" href="#configuracion-final" title="Link to this heading">ÔÉÅ</a></h3>
<p>Basado en el an√°lisis exploratorio, seleccionamos:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">order</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>           <span class="c1"># (p, d, q)</span>
<span class="n">seasonal_order</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>  <span class="c1"># (P, D, Q, s)</span>
</pre></div>
</div>
<p><strong>Justificaci√≥n:</strong></p>
<ul class="simple">
<li><p><strong>d=1</strong>: Una diferenciaci√≥n es suficiente para estacionariedad</p></li>
<li><p><strong>p=1, q=1</strong>: Patrones simples en ACF/PACF</p></li>
<li><p><strong>s=5</strong>: Ciclo semanal (5 d√≠as h√°biles)</p></li>
<li><p><strong>P=1, D=1, Q=1</strong>: Estacionalidad moderada</p></li>
</ul>
</section>
<section id="criterios-de-validacion">
<h3>Criterios de Validaci√≥n<a class="headerlink" href="#criterios-de-validacion" title="Link to this heading">ÔÉÅ</a></h3>
<ul class="simple">
<li><p>‚úÖ Residuos deben ser ruido blanco (Ljung-Box test)</p></li>
<li><p>‚úÖ AIC y BIC minimizados</p></li>
<li><p>‚úÖ Predicciones estables (sin explosi√≥n)</p></li>
</ul>
<p>‚Äî</p>
</section>
</section>
<section id="modelo-2-ffnn-feed-forward-neural-network">
<h2>Modelo 2: FFNN (Feed-Forward Neural Network)<a class="headerlink" href="#modelo-2-ffnn-feed-forward-neural-network" title="Link to this heading">ÔÉÅ</a></h2>
<p>Una <strong>FFNN</strong> es una red neuronal artificial donde la informaci√≥n fluye en una sola direcci√≥n (sin ciclos).</p>
<section id="arquitectura-de-la-red">
<h3>Arquitectura de la Red<a class="headerlink" href="#arquitectura-de-la-red" title="Link to this heading">ÔÉÅ</a></h3>
<p>Nuestra FFNN tiene la siguiente estructura:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>Input Layer (lookback d√≠as)
      ‚Üì
Dense(128) + ReLU + L2(0.0001) + Dropout(0.1)
      ‚Üì
Dense(64) + ReLU + L2(0.0001) + Dropout(0.2)
      ‚Üì
Dense(32) + ReLU + L2(0.00001) + Dropout(0.1)
      ‚Üì
Dense(16) + ReLU
      ‚Üì
Output Layer: Dense(1) - Predicci√≥n del precio
</pre></div>
</div>
<p><strong>N√∫mero total de capas</strong>: 5 (4 ocultas + 1 salida)</p>
</section>
<section id="hiperparametros-seleccionados">
<h3>Hiperpar√°metros Seleccionados<a class="headerlink" href="#hiperparametros-seleccionados" title="Link to this heading">ÔÉÅ</a></h3>
<table class="docutils align-default">
<colgroup>
<col style="width: 30.0%" />
<col style="width: 30.0%" />
<col style="width: 40.0%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Hiperpar√°metro</p></th>
<th class="head"><p>Valor</p></th>
<th class="head"><p>Justificaci√≥n</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><strong>Lookback</strong></p></td>
<td><p>20 d√≠as</p></td>
<td><p>Balance entre memoria hist√≥rica y overfitting</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Capas ocultas</strong></p></td>
<td><p>4</p></td>
<td><p>Suficiente profundidad sin complejidad excesiva</p></td>
</tr>
<tr class="row-even"><td><p><strong>Neuronas (L1)</strong></p></td>
<td><p>128</p></td>
<td><p>Capa ancha para capturar patrones iniciales</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Neuronas (L2)</strong></p></td>
<td><p>64</p></td>
<td><p>Reducci√≥n progresiva (pir√°mide)</p></td>
</tr>
<tr class="row-even"><td><p><strong>Neuronas (L3)</strong></p></td>
<td><p>32</p></td>
<td><p>Extracci√≥n de features de alto nivel</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Neuronas (L4)</strong></p></td>
<td><p>16</p></td>
<td><p>Consolidaci√≥n final antes de salida</p></td>
</tr>
<tr class="row-even"><td><p><strong>Funci√≥n de activaci√≥n</strong></p></td>
<td><p>ReLU</p></td>
<td><p>Previene vanishing gradient, computacionalmente eficiente</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Regularizaci√≥n L2</strong></p></td>
<td><p>[1e-4, 1e-5, 1e-6]</p></td>
<td><p>Previene overfitting en pesos grandes</p></td>
</tr>
<tr class="row-even"><td><p><strong>Dropout</strong></p></td>
<td><p>[0.1, 0.2]</p></td>
<td><p>Desactiva neuronas aleatoriamente (generalizaci√≥n)</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Learning rate</strong></p></td>
<td><p>0.001</p></td>
<td><p>Tasa est√°ndar para Adam optimizer</p></td>
</tr>
<tr class="row-even"><td><p><strong>Batch size</strong></p></td>
<td><p>32</p></td>
<td><p>Balance entre velocidad y estabilidad</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Epochs</strong></p></td>
<td><p>100 (con Early Stopping)</p></td>
<td><p>Suficiente para convergencia</p></td>
</tr>
</tbody>
</table>
</section>
<section id="funcion-de-activacion-relu">
<h3>Funci√≥n de Activaci√≥n: ReLU<a class="headerlink" href="#funcion-de-activacion-relu" title="Link to this heading">ÔÉÅ</a></h3>
<div class="math notranslate nohighlight">
\[f(x) = \max(0, x)\]</div>
<p><strong>Ventajas:</strong></p>
<ul class="simple">
<li><p>No saturaci√≥n en valores positivos</p></li>
<li><p>Derivada simple (0 o 1)</p></li>
<li><p>Computacionalmente eficiente</p></li>
</ul>
</section>
<section id="regularizacion">
<h3>Regularizaci√≥n<a class="headerlink" href="#regularizacion" title="Link to this heading">ÔÉÅ</a></h3>
<p><strong>1. L2 Regularization (Ridge)</strong></p>
<p>A√±ade penalizaci√≥n a la funci√≥n de p√©rdida:</p>
<div class="math notranslate nohighlight">
\[L_{total} = L_{MSE} + \lambda \sum_{i} w_i^2\]</div>
<p>Esto previene que los pesos crezcan excesivamente.</p>
<p><strong>2. Dropout</strong></p>
<p>Durante entrenamiento, ¬´apaga¬ª aleatoriamente un porcentaje de neuronas en cada iteraci√≥n.</p>
<ul class="simple">
<li><p><strong>Efecto</strong>: Fuerza redundancia en la red</p></li>
<li><p><strong>Resultado</strong>: Mejor generalizaci√≥n al test set</p></li>
</ul>
</section>
<section id="optimizador-adam">
<h3>Optimizador: Adam<a class="headerlink" href="#optimizador-adam" title="Link to this heading">ÔÉÅ</a></h3>
<p><strong>Adam</strong> (Adaptive Moment Estimation) combina las ventajas de AdaGrad y RMSprop.</p>
<p><strong>Actualizaci√≥n de pesos:</strong></p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}m_t = \beta_1 m_{t-1} + (1-\beta_1) g_t\\v_t = \beta_2 v_{t-1} + (1-\beta_2) g_t^2\\w_t = w_{t-1} - \alpha \frac{m_t}{\sqrt{v_t} + \epsilon}\end{aligned}\end{align} \]</div>
<p>Donde:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(m_t\)</span>: Primer momento (media de gradientes)</p></li>
<li><p><span class="math notranslate nohighlight">\(v_t\)</span>: Segundo momento (varianza de gradientes)</p></li>
<li><p><span class="math notranslate nohighlight">\(\alpha\)</span>: Learning rate (0.001)</p></li>
<li><p><span class="math notranslate nohighlight">\(\beta_1, \beta_2\)</span>: Tasas de decaimiento (0.9, 0.999)</p></li>
</ul>
<p><strong>Ventajas de Adam:</strong></p>
<p>‚úÖ Adaptaci√≥n individual de learning rate por par√°metro</p>
<p>‚úÖ Funciona bien con gradientes ruidosos</p>
<p>‚úÖ Requiere poca tunning manual</p>
</section>
<section id="walk-forward-validation">
<h3>Walk-Forward Validation<a class="headerlink" href="#walk-forward-validation" title="Link to this heading">ÔÉÅ</a></h3>
<p>Para predicciones de m√∫ltiples d√≠as, usamos un enfoque de <strong>rolling window</strong>:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>D√≠a 1: Usar ventana [t-20:t] ‚Üí Predecir t+1
D√≠a 2: Usar ventana [t-19:t+1] ‚Üí Predecir t+2
D√≠a 3: Usar ventana [t-18:t+2] ‚Üí Predecir t+3
...
</pre></div>
</div>
<p>Este m√©todo simula condiciones reales de trading.</p>
</section>
<section id="early-stopping">
<h3>Early Stopping<a class="headerlink" href="#early-stopping" title="Link to this heading">ÔÉÅ</a></h3>
<p>Implementamos Early Stopping para prevenir overfitting:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">EarlyStopping</span><span class="p">(</span>
    <span class="n">monitor</span><span class="o">=</span><span class="s1">&#39;val_loss&#39;</span><span class="p">,</span>    <span class="c1"># Vigilar p√©rdida en validaci√≥n</span>
    <span class="n">patience</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span>           <span class="c1"># Esperar 15 epochs sin mejora</span>
    <span class="n">restore_best_weights</span><span class="o">=</span><span class="kc">True</span>  <span class="c1"># Regresar a mejor modelo</span>
<span class="p">)</span>
</pre></div>
</div>
<p>Si la p√©rdida en validaci√≥n no mejora en 15 epochs consecutivos, el entrenamiento se detiene.</p>
<p>‚Äî</p>
</section>
</section>
<section id="preprocesamiento-de-datos">
<h2>Preprocesamiento de Datos<a class="headerlink" href="#preprocesamiento-de-datos" title="Link to this heading">ÔÉÅ</a></h2>
<section id="escalado-con-minmaxscaler">
<h3>Escalado con MinMaxScaler<a class="headerlink" href="#escalado-con-minmaxscaler" title="Link to this heading">ÔÉÅ</a></h3>
<p>Para la FFNN, escalamos los datos al rango [0, 1]:</p>
<div class="math notranslate nohighlight">
\[X_{scaled} = \frac{X - X_{min}}{X_{max} - X_{min}}\]</div>
<p><strong>Razones:</strong></p>
<ol class="arabic simple">
<li><p>Convergencia m√°s r√°pida del optimizador</p></li>
<li><p>Evita dominancia de features con mayor magnitud</p></li>
<li><p>Previene problemas num√©ricos (overflow/underflow)</p></li>
</ol>
<p><strong>Importante:</strong> El scaler se ajusta SOLO con datos de entrenamiento para evitar data leakage.</p>
</section>
<section id="division-de-datos">
<h3>Divisi√≥n de Datos<a class="headerlink" href="#division-de-datos" title="Link to this heading">ÔÉÅ</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">Total</span> <span class="n">de</span> <span class="n">datos</span><span class="p">:</span> <span class="o">~</span><span class="mi">500</span> <span class="n">d√≠as</span> <span class="p">(</span><span class="mi">2</span> <span class="n">a√±os</span><span class="p">)</span>

<span class="n">Train</span><span class="p">:</span> <span class="mi">470</span> <span class="n">d√≠as</span> <span class="p">(</span><span class="mi">94</span><span class="o">%</span><span class="p">)</span>
<span class="n">Test</span><span class="p">:</span>   <span class="mi">30</span> <span class="n">d√≠as</span> <span class="p">(</span><span class="mi">6</span><span class="o">%</span><span class="p">)</span>
<span class="n">Future</span><span class="p">:</span>  <span class="mi">5</span> <span class="n">d√≠as</span> <span class="p">(</span><span class="n">predicci√≥n</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Train Set:</strong> Para entrenar los modelos</p>
<p><strong>Test Set:</strong> Para evaluar performance antes de predicci√≥n final</p>
<p><strong>Future Set:</strong> Predicciones objetivo (20-24 octubre 2025)</p>
</section>
<section id="creacion-de-secuencias">
<h3>Creaci√≥n de Secuencias<a class="headerlink" href="#creacion-de-secuencias" title="Link to this heading">ÔÉÅ</a></h3>
<p>Para la FFNN, transformamos datos de serie temporal en pares (X, y):</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Ejemplo con lookback=3</span>
<span class="n">Precios</span><span class="p">:</span> <span class="p">[</span><span class="mi">100</span><span class="p">,</span> <span class="mi">102</span><span class="p">,</span> <span class="mi">105</span><span class="p">,</span> <span class="mi">108</span><span class="p">,</span> <span class="mi">110</span><span class="p">,</span> <span class="mi">112</span><span class="p">]</span>

<span class="n">Secuencias</span><span class="p">:</span>
<span class="n">X</span><span class="o">=</span><span class="p">[</span><span class="mi">100</span><span class="p">,</span> <span class="mi">102</span><span class="p">,</span> <span class="mi">105</span><span class="p">]</span> <span class="err">‚Üí</span> <span class="n">y</span><span class="o">=</span><span class="mi">108</span>
<span class="n">X</span><span class="o">=</span><span class="p">[</span><span class="mi">102</span><span class="p">,</span> <span class="mi">105</span><span class="p">,</span> <span class="mi">108</span><span class="p">]</span> <span class="err">‚Üí</span> <span class="n">y</span><span class="o">=</span><span class="mi">110</span>
<span class="n">X</span><span class="o">=</span><span class="p">[</span><span class="mi">105</span><span class="p">,</span> <span class="mi">108</span><span class="p">,</span> <span class="mi">110</span><span class="p">]</span> <span class="err">‚Üí</span> <span class="n">y</span><span class="o">=</span><span class="mi">112</span>
</pre></div>
</div>
<p>Esto permite a la red aprender patrones hist√≥ricos.</p>
<p>‚Äî</p>
</section>
</section>
<section id="metricas-de-evaluacion">
<h2>M√©tricas de Evaluaci√≥n<a class="headerlink" href="#metricas-de-evaluacion" title="Link to this heading">ÔÉÅ</a></h2>
<p>Para comparar ambos modelos, usamos tres m√©tricas est√°ndar:</p>
<section id="rmse-root-mean-squared-error">
<h3>1. RMSE (Root Mean Squared Error)<a class="headerlink" href="#rmse-root-mean-squared-error" title="Link to this heading">ÔÉÅ</a></h3>
<div class="math notranslate nohighlight">
\[RMSE = \sqrt{\frac{1}{n}\sum_{i=1}^{n}(y_i - \hat{y}_i)^2}\]</div>
<ul class="simple">
<li><p><strong>Unidad</strong>: Misma que la variable (d√≥lares)</p></li>
<li><p><strong>Interpretaci√≥n</strong>: Error promedio en predicciones</p></li>
<li><p><strong>Sensible a outliers</strong>: Penaliza errores grandes</p></li>
</ul>
</section>
<section id="mae-mean-absolute-error">
<h3>2. MAE (Mean Absolute Error)<a class="headerlink" href="#mae-mean-absolute-error" title="Link to this heading">ÔÉÅ</a></h3>
<div class="math notranslate nohighlight">
\[MAE = \frac{1}{n}\sum_{i=1}^{n}|y_i - \hat{y}_i|\]</div>
<ul class="simple">
<li><p><strong>Unidad</strong>: D√≥lares</p></li>
<li><p><strong>Interpretaci√≥n</strong>: Error absoluto promedio</p></li>
<li><p><strong>M√°s robusto</strong> a outliers que RMSE</p></li>
</ul>
</section>
<section id="mape-mean-absolute-percentage-error">
<h3>3. MAPE (Mean Absolute Percentage Error)<a class="headerlink" href="#mape-mean-absolute-percentage-error" title="Link to this heading">ÔÉÅ</a></h3>
<div class="math notranslate nohighlight">
\[MAPE = \frac{100}{n}\sum_{i=1}^{n}\left|\frac{y_i - \hat{y}_i}{y_i}\right|\]</div>
<ul class="simple">
<li><p><strong>Unidad</strong>: Porcentaje (%)</p></li>
<li><p><strong>Interpretaci√≥n</strong>: Error relativo promedio</p></li>
<li><p><strong>Ventaja</strong>: Independiente de la escala del precio</p></li>
</ul>
</section>
<section id="criterios-de-exito">
<h3>Criterios de √âxito<a class="headerlink" href="#criterios-de-exito" title="Link to this heading">ÔÉÅ</a></h3>
<p>Un modelo se considera ¬´bueno¬ª si:</p>
<ul class="simple">
<li><p>‚úÖ RMSE &lt; $10 (para acciones ~$100-500)</p></li>
<li><p>‚úÖ MAE &lt; $7</p></li>
<li><p>‚úÖ MAPE &lt; 5%</p></li>
<li><p>‚úÖ Predicciones estables (sin saltos abruptos)</p></li>
</ul>
<p>‚Äî</p>
</section>
</section>
<section id="reproducibilidad">
<h2>Reproducibilidad<a class="headerlink" href="#reproducibilidad" title="Link to this heading">ÔÉÅ</a></h2>
<p>Para garantizar que los resultados sean reproducibles:</p>
<section id="semilla-fija">
<h3>Semilla Fija<a class="headerlink" href="#semilla-fija" title="Link to this heading">ÔÉÅ</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">SEED</span> <span class="o">=</span> <span class="mi">42</span>

<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">SEED</span><span class="p">)</span>
<span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">set_seed</span><span class="p">(</span><span class="n">SEED</span><span class="p">)</span>
<span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">SEED</span><span class="p">)</span>
</pre></div>
</div>
<p>Esto asegura que:</p>
<ul class="simple">
<li><p>Divisi√≥n train/test sea id√©ntica</p></li>
<li><p>Inicializaci√≥n de pesos de FFNN sea consistente</p></li>
<li><p>Dropout y shuffle sean determin√≠sticos</p></li>
</ul>
</section>
<section id="control-de-versiones">
<h3>Control de Versiones<a class="headerlink" href="#control-de-versiones" title="Link to this heading">ÔÉÅ</a></h3>
<p>Todas las dependencias tienen versiones fijas en <code class="docutils literal notranslate"><span class="pre">requirements.txt</span></code>:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>tensorflow==2.13.0
statsmodels==0.14.0
numpy==1.24.3
...
</pre></div>
</div>
</section>
<section id="entorno-de-ejecucion">
<h3>Entorno de Ejecuci√≥n<a class="headerlink" href="#entorno-de-ejecucion" title="Link to this heading">ÔÉÅ</a></h3>
<ul class="simple">
<li><p><strong>Python</strong>: 3.8+</p></li>
<li><p><strong>Sistema</strong>: Compatible con Linux, macOS, Windows</p></li>
<li><p><strong>Hardware</strong>: CPU suficiente (GPU opcional para FFNN)</p></li>
</ul>
<p>‚Äî</p>
</section>
</section>
<section id="limitaciones-y-consideraciones">
<h2>Limitaciones y Consideraciones<a class="headerlink" href="#limitaciones-y-consideraciones" title="Link to this heading">ÔÉÅ</a></h2>
<section id="limitaciones-del-proyecto">
<h3>Limitaciones del Proyecto<a class="headerlink" href="#limitaciones-del-proyecto" title="Link to this heading">ÔÉÅ</a></h3>
<ol class="arabic simple">
<li><p><strong>Horizonte corto</strong>: Solo 5 d√≠as (dificultad aumenta exponencialmente)</p></li>
<li><p><strong>Datos hist√≥ricos √∫nicamente</strong>: No incorpora noticias o sentimiento</p></li>
<li><p><strong>Eventos imprevistos</strong>: No puede anticipar anuncios sorpresa</p></li>
<li><p><strong>Suposici√≥n de mercado eficiente</strong>: Los patrones del pasado pueden cambiar</p></li>
</ol>
</section>
<section id="supuestos-del-modelo">
<h3>Supuestos del Modelo<a class="headerlink" href="#supuestos-del-modelo" title="Link to this heading">ÔÉÅ</a></h3>
<ul class="simple">
<li><p>üìä Los datos hist√≥ricos contienen informaci√≥n predictiva</p></li>
<li><p>üìÖ Los patrones temporales son relativamente estables</p></li>
<li><p>üíπ No hay cambios estructurales dr√°sticos durante predicci√≥n</p></li>
<li><p>üîÑ Los mercados operan normalmente (no crisis inesperadas)</p></li>
</ul>
</section>
<section id="consideraciones-eticas">
<h3>Consideraciones √âticas<a class="headerlink" href="#consideraciones-eticas" title="Link to this heading">ÔÉÅ</a></h3>
<ul class="simple">
<li><p>‚ö†Ô∏è Este proyecto es <strong>acad√©mico</strong>, no constituye asesor√≠a financiera</p></li>
<li><p>‚ö†Ô∏è No debe usarse para decisiones reales de inversi√≥n sin an√°lisis adicional</p></li>
<li><p>‚ö†Ô∏è Los mercados financieros son inherentemente impredecibles</p></li>
</ul>
<p>‚Äî</p>
</section>
</section>
<section id="resumen-de-la-metodologia">
<h2>Resumen de la Metodolog√≠a<a class="headerlink" href="#resumen-de-la-metodologia" title="Link to this heading">ÔÉÅ</a></h2>
<table class="docutils align-default">
<colgroup>
<col style="width: 25.0%" />
<col style="width: 35.0%" />
<col style="width: 40.0%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Aspecto</p></th>
<th class="head"><p>SARIMAX</p></th>
<th class="head"><p>FFNN</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><strong>Tipo de modelo</strong></p></td>
<td><p>Estad√≠stico param√©trico</p></td>
<td><p>Aprendizaje profundo</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Hiperpar√°metros clave</strong></p></td>
<td><p>(p,d,q), (P,D,Q,s)</p></td>
<td><p>Capas, neuronas, dropout, LR</p></td>
</tr>
<tr class="row-even"><td><p><strong>Preprocesamiento</strong></p></td>
<td><p>Diferenciaci√≥n</p></td>
<td><p>Escalado MinMax</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Ventajas</strong></p></td>
<td><p>Interpretable, te√≥ricamente fundamentado</p></td>
<td><p>Captura no linealidades complejas</p></td>
</tr>
<tr class="row-even"><td><p><strong>Desventajas</strong></p></td>
<td><p>Asume linealidad, estacionariedad</p></td>
<td><p>Caja negra, requiere muchos datos</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Tiempo de entrenamiento</strong></p></td>
<td><p>R√°pido (~segundos)</p></td>
<td><p>Moderado (~minutos)</p></td>
</tr>
</tbody>
</table>
<p>Ambos modelos son complementarios y su comparaci√≥n permite evaluar si m√©todos estad√≠sticos cl√°sicos o deep learning son m√°s efectivos para este problema espec√≠fico.</p>
</section>
</section>


           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Derechos de autor 2024, Tu Equipo.</p>
  </div>

  Compilado con <a href="https://www.sphinx-doc.org/">Sphinx</a> usando un
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">tema</a>
    proporcionado por <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>