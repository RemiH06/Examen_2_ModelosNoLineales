

<!DOCTYPE html>
<html class="writer-html5" lang="es" data-content_root="./">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Metodología &mdash; Predicción NVDA</title>
      <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="_static/css/theme.css?v=e59714d7" />

  
      <script src="_static/jquery.js?v=5d32c60e"></script>
      <script src="_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="_static/documentation_options.js?v=36c4ab74"></script>
      <script src="_static/doctools.js?v=9bcbadda"></script>
      <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
      <script src="_static/translations.js?v=f85f4cfb"></script>
      <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Índice" href="genindex.html" />
    <link rel="search" title="Búsqueda" href="search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="index.html" class="icon icon-home">
            Examen2
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Buscar documentos" aria-label="Buscar documentos" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <!-- Local TOC -->
              <div class="local-toc"><ul>
<li><a class="reference internal" href="#">Metodología</a><ul>
<li><a class="reference internal" href="#pipeline-general-del-proyecto">Pipeline General del Proyecto</a></li>
<li><a class="reference internal" href="#modelo-1-sarimax">Modelo 1: SARIMAX</a><ul>
<li><a class="reference internal" href="#estructura-del-modelo">Estructura del Modelo</a></li>
<li><a class="reference internal" href="#ecuacion-general">Ecuación General</a></li>
<li><a class="reference internal" href="#seleccion-de-ordenes">Selección de Órdenes</a></li>
<li><a class="reference internal" href="#configuracion-final">Configuración Final</a></li>
<li><a class="reference internal" href="#criterios-de-validacion">Criterios de Validación</a></li>
</ul>
</li>
<li><a class="reference internal" href="#modelo-2-ffnn-feed-forward-neural-network">Modelo 2: FFNN (Feed-Forward Neural Network)</a><ul>
<li><a class="reference internal" href="#arquitectura-de-la-red">Arquitectura de la Red</a></li>
<li><a class="reference internal" href="#hiperparametros-seleccionados">Hiperparámetros Seleccionados</a></li>
<li><a class="reference internal" href="#funcion-de-activacion-relu">Función de Activación: ReLU</a></li>
<li><a class="reference internal" href="#regularizacion">Regularización</a></li>
<li><a class="reference internal" href="#optimizador-adam">Optimizador: Adam</a></li>
<li><a class="reference internal" href="#walk-forward-validation">Walk-Forward Validation</a></li>
<li><a class="reference internal" href="#early-stopping">Early Stopping</a></li>
</ul>
</li>
<li><a class="reference internal" href="#preprocesamiento-de-datos">Preprocesamiento de Datos</a><ul>
<li><a class="reference internal" href="#escalado-con-minmaxscaler">Escalado con MinMaxScaler</a></li>
<li><a class="reference internal" href="#division-de-datos">División de Datos</a></li>
<li><a class="reference internal" href="#creacion-de-secuencias">Creación de Secuencias</a></li>
</ul>
</li>
<li><a class="reference internal" href="#metricas-de-evaluacion">Métricas de Evaluación</a><ul>
<li><a class="reference internal" href="#rmse-root-mean-squared-error">1. RMSE (Root Mean Squared Error)</a></li>
<li><a class="reference internal" href="#mae-mean-absolute-error">2. MAE (Mean Absolute Error)</a></li>
<li><a class="reference internal" href="#mape-mean-absolute-percentage-error">3. MAPE (Mean Absolute Percentage Error)</a></li>
<li><a class="reference internal" href="#criterios-de-exito">Criterios de Éxito</a></li>
</ul>
</li>
<li><a class="reference internal" href="#reproducibilidad">Reproducibilidad</a><ul>
<li><a class="reference internal" href="#semilla-fija">Semilla Fija</a></li>
<li><a class="reference internal" href="#control-de-versiones">Control de Versiones</a></li>
<li><a class="reference internal" href="#entorno-de-ejecucion">Entorno de Ejecución</a></li>
</ul>
</li>
<li><a class="reference internal" href="#limitaciones-y-consideraciones">Limitaciones y Consideraciones</a><ul>
<li><a class="reference internal" href="#limitaciones-del-proyecto">Limitaciones del Proyecto</a></li>
<li><a class="reference internal" href="#supuestos-del-modelo">Supuestos del Modelo</a></li>
<li><a class="reference internal" href="#consideraciones-eticas">Consideraciones Éticas</a></li>
</ul>
</li>
<li><a class="reference internal" href="#resumen-de-la-metodologia">Resumen de la Metodología</a></li>
</ul>
</li>
</ul>
</div>
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">Examen2</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">Metodología</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/metodologia.rst.txt" rel="nofollow"> Ver código fuente de la página</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="metodologia">
<h1>Metodología<a class="headerlink" href="#metodologia" title="Link to this heading"></a></h1>
<p>Esta sección detalla la metodología completa utilizada para construir y evaluar los modelos SARIMAX y FFNN.</p>
<section id="pipeline-general-del-proyecto">
<h2>Pipeline General del Proyecto<a class="headerlink" href="#pipeline-general-del-proyecto" title="Link to this heading"></a></h2>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>1. Descarga de datos (yfinance)
       ↓
2. Análisis exploratorio (EDA)
       ↓
3. Pruebas de estacionariedad
       ↓
4. Preparación de datos (train/test/future)
       ↓
5. Entrenamiento de modelos
       ↓
6. Evaluación y comparación
       ↓
7. Predicciones finales (5 días)
</pre></div>
</div>
<p>—</p>
</section>
<section id="modelo-1-sarimax">
<h2>Modelo 1: SARIMAX<a class="headerlink" href="#modelo-1-sarimax" title="Link to this heading"></a></h2>
<p><strong>SARIMAX</strong> significa <em>Seasonal AutoRegressive Integrated Moving Average with eXogenous variables</em>.</p>
<section id="estructura-del-modelo">
<h3>Estructura del Modelo<a class="headerlink" href="#estructura-del-modelo" title="Link to this heading"></a></h3>
<p>Un modelo SARIMAX se define por dos conjuntos de órdenes:</p>
<p><strong>Componente No Estacional: (p, d, q)</strong></p>
<ul class="simple">
<li><p><strong>p</strong>: Orden autoregresivo (AR) - número de lags de la variable dependiente</p></li>
<li><p><strong>d</strong>: Grado de diferenciación (I) - veces que se diferencia la serie</p></li>
<li><p><strong>q</strong>: Orden de media móvil (MA) - número de lags de los errores</p></li>
</ul>
<p><strong>Componente Estacional: (P, D, Q, s)</strong></p>
<ul class="simple">
<li><p><strong>P</strong>: Orden autoregresivo estacional</p></li>
<li><p><strong>D</strong>: Diferenciación estacional</p></li>
<li><p><strong>Q</strong>: Media móvil estacional</p></li>
<li><p><strong>s</strong>: Periodo estacional (e.g., 5 para días de la semana, 12 para meses)</p></li>
</ul>
</section>
<section id="ecuacion-general">
<h3>Ecuación General<a class="headerlink" href="#ecuacion-general" title="Link to this heading"></a></h3>
<div class="math notranslate nohighlight">
\[\Phi_P(B^s)\phi_p(B)\nabla^D_s\nabla^d Y_t = \Theta_Q(B^s)\theta_q(B)\epsilon_t\]</div>
<p>Donde:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(Y_t\)</span>: Serie temporal en el tiempo t</p></li>
<li><p><span class="math notranslate nohighlight">\(B\)</span>: Operador de retardo (lag)</p></li>
<li><p><span class="math notranslate nohighlight">\(\nabla\)</span>: Operador de diferenciación</p></li>
<li><p><span class="math notranslate nohighlight">\(\epsilon_t\)</span>: Error o ruido blanco</p></li>
</ul>
</section>
<section id="seleccion-de-ordenes">
<h3>Selección de Órdenes<a class="headerlink" href="#seleccion-de-ordenes" title="Link to this heading"></a></h3>
<p>Para determinar los valores óptimos de (p, d, q) y (P, D, Q, s):</p>
<ol class="arabic simple">
<li><p><strong>Diferenciación (d)</strong></p>
<ul class="simple">
<li><p>Aplicar prueba ADF (Augmented Dickey-Fuller)</p></li>
<li><p>Si p-value &gt; 0.05 → serie NO estacionaria → aumentar d</p></li>
<li><p>Confirmar con prueba KPSS</p></li>
</ul>
</li>
<li><p><strong>Órdenes AR y MA (p, q)</strong></p>
<ul class="simple">
<li><p>Analizar gráficas ACF (Autocorrelation Function)</p></li>
<li><p>Analizar gráficas PACF (Partial Autocorrelation Function)</p></li>
<li><p>Reglas empíricas:</p>
<ul>
<li><p>Si ACF decae lentamente → componente AR significativo</p></li>
<li><p>Si PACF corta en lag k → p = k</p></li>
<li><p>Si ACF corta en lag k → q = k</p></li>
</ul>
</li>
</ul>
</li>
<li><p><strong>Componente Estacional (P, D, Q, s)</strong></p>
<ul class="simple">
<li><p>Observar patrones repetitivos en ACF/PACF</p></li>
<li><p>Para acciones: s = 5 (semana bursátil) o s = 21 (mes aproximado)</p></li>
</ul>
</li>
<li><p><strong>Criterios de Información</strong></p>
<ul class="simple">
<li><p><strong>AIC</strong> (Akaike Information Criterion): penaliza complejidad</p></li>
<li><p><strong>BIC</strong> (Bayesian Information Criterion): penaliza más fuertemente</p></li>
<li><p>Menor AIC/BIC → mejor modelo</p></li>
</ul>
</li>
</ol>
</section>
<section id="configuracion-final">
<h3>Configuración Final<a class="headerlink" href="#configuracion-final" title="Link to this heading"></a></h3>
<p>Basado en el análisis exploratorio, seleccionamos:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">order</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>           <span class="c1"># (p, d, q)</span>
<span class="n">seasonal_order</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>  <span class="c1"># (P, D, Q, s)</span>
</pre></div>
</div>
<p><strong>Justificación:</strong></p>
<ul class="simple">
<li><p><strong>d=1</strong>: Una diferenciación es suficiente para estacionariedad</p></li>
<li><p><strong>p=1, q=1</strong>: Patrones simples en ACF/PACF</p></li>
<li><p><strong>s=5</strong>: Ciclo semanal (5 días hábiles)</p></li>
<li><p><strong>P=1, D=1, Q=1</strong>: Estacionalidad moderada</p></li>
</ul>
</section>
<section id="criterios-de-validacion">
<h3>Criterios de Validación<a class="headerlink" href="#criterios-de-validacion" title="Link to this heading"></a></h3>
<ul class="simple">
<li><p>✅ Residuos deben ser ruido blanco (Ljung-Box test)</p></li>
<li><p>✅ AIC y BIC minimizados</p></li>
<li><p>✅ Predicciones estables (sin explosión)</p></li>
</ul>
<p>—</p>
</section>
</section>
<section id="modelo-2-ffnn-feed-forward-neural-network">
<h2>Modelo 2: FFNN (Feed-Forward Neural Network)<a class="headerlink" href="#modelo-2-ffnn-feed-forward-neural-network" title="Link to this heading"></a></h2>
<p>Una <strong>FFNN</strong> es una red neuronal artificial donde la información fluye en una sola dirección (sin ciclos).</p>
<section id="arquitectura-de-la-red">
<h3>Arquitectura de la Red<a class="headerlink" href="#arquitectura-de-la-red" title="Link to this heading"></a></h3>
<p>Nuestra FFNN tiene la siguiente estructura:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>Input Layer (lookback días)
      ↓
Dense(128) + ReLU + L2(0.0001) + Dropout(0.1)
      ↓
Dense(64) + ReLU + L2(0.0001) + Dropout(0.2)
      ↓
Dense(32) + ReLU + L2(0.00001) + Dropout(0.1)
      ↓
Dense(16) + ReLU
      ↓
Output Layer: Dense(1) - Predicción del precio
</pre></div>
</div>
<p><strong>Número total de capas</strong>: 5 (4 ocultas + 1 salida)</p>
</section>
<section id="hiperparametros-seleccionados">
<h3>Hiperparámetros Seleccionados<a class="headerlink" href="#hiperparametros-seleccionados" title="Link to this heading"></a></h3>
<table class="docutils align-default">
<colgroup>
<col style="width: 30.0%" />
<col style="width: 30.0%" />
<col style="width: 40.0%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Hiperparámetro</p></th>
<th class="head"><p>Valor</p></th>
<th class="head"><p>Justificación</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><strong>Lookback</strong></p></td>
<td><p>20 días</p></td>
<td><p>Balance entre memoria histórica y overfitting</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Capas ocultas</strong></p></td>
<td><p>4</p></td>
<td><p>Suficiente profundidad sin complejidad excesiva</p></td>
</tr>
<tr class="row-even"><td><p><strong>Neuronas (L1)</strong></p></td>
<td><p>128</p></td>
<td><p>Capa ancha para capturar patrones iniciales</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Neuronas (L2)</strong></p></td>
<td><p>64</p></td>
<td><p>Reducción progresiva (pirámide)</p></td>
</tr>
<tr class="row-even"><td><p><strong>Neuronas (L3)</strong></p></td>
<td><p>32</p></td>
<td><p>Extracción de features de alto nivel</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Neuronas (L4)</strong></p></td>
<td><p>16</p></td>
<td><p>Consolidación final antes de salida</p></td>
</tr>
<tr class="row-even"><td><p><strong>Función de activación</strong></p></td>
<td><p>ReLU</p></td>
<td><p>Previene vanishing gradient, computacionalmente eficiente</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Regularización L2</strong></p></td>
<td><p>[1e-4, 1e-5, 1e-6]</p></td>
<td><p>Previene overfitting en pesos grandes</p></td>
</tr>
<tr class="row-even"><td><p><strong>Dropout</strong></p></td>
<td><p>[0.1, 0.2]</p></td>
<td><p>Desactiva neuronas aleatoriamente (generalización)</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Learning rate</strong></p></td>
<td><p>0.001</p></td>
<td><p>Tasa estándar para Adam optimizer</p></td>
</tr>
<tr class="row-even"><td><p><strong>Batch size</strong></p></td>
<td><p>32</p></td>
<td><p>Balance entre velocidad y estabilidad</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Epochs</strong></p></td>
<td><p>100 (con Early Stopping)</p></td>
<td><p>Suficiente para convergencia</p></td>
</tr>
</tbody>
</table>
</section>
<section id="funcion-de-activacion-relu">
<h3>Función de Activación: ReLU<a class="headerlink" href="#funcion-de-activacion-relu" title="Link to this heading"></a></h3>
<div class="math notranslate nohighlight">
\[f(x) = \max(0, x)\]</div>
<p><strong>Ventajas:</strong></p>
<ul class="simple">
<li><p>No saturación en valores positivos</p></li>
<li><p>Derivada simple (0 o 1)</p></li>
<li><p>Computacionalmente eficiente</p></li>
</ul>
</section>
<section id="regularizacion">
<h3>Regularización<a class="headerlink" href="#regularizacion" title="Link to this heading"></a></h3>
<p><strong>1. L2 Regularization (Ridge)</strong></p>
<p>Añade penalización a la función de pérdida:</p>
<div class="math notranslate nohighlight">
\[L_{total} = L_{MSE} + \lambda \sum_{i} w_i^2\]</div>
<p>Esto previene que los pesos crezcan excesivamente.</p>
<p><strong>2. Dropout</strong></p>
<p>Durante entrenamiento, «apaga» aleatoriamente un porcentaje de neuronas en cada iteración.</p>
<ul class="simple">
<li><p><strong>Efecto</strong>: Fuerza redundancia en la red</p></li>
<li><p><strong>Resultado</strong>: Mejor generalización al test set</p></li>
</ul>
</section>
<section id="optimizador-adam">
<h3>Optimizador: Adam<a class="headerlink" href="#optimizador-adam" title="Link to this heading"></a></h3>
<p><strong>Adam</strong> (Adaptive Moment Estimation) combina las ventajas de AdaGrad y RMSprop.</p>
<p><strong>Actualización de pesos:</strong></p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}m_t = \beta_1 m_{t-1} + (1-\beta_1) g_t\\v_t = \beta_2 v_{t-1} + (1-\beta_2) g_t^2\\w_t = w_{t-1} - \alpha \frac{m_t}{\sqrt{v_t} + \epsilon}\end{aligned}\end{align} \]</div>
<p>Donde:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(m_t\)</span>: Primer momento (media de gradientes)</p></li>
<li><p><span class="math notranslate nohighlight">\(v_t\)</span>: Segundo momento (varianza de gradientes)</p></li>
<li><p><span class="math notranslate nohighlight">\(\alpha\)</span>: Learning rate (0.001)</p></li>
<li><p><span class="math notranslate nohighlight">\(\beta_1, \beta_2\)</span>: Tasas de decaimiento (0.9, 0.999)</p></li>
</ul>
<p><strong>Ventajas de Adam:</strong></p>
<p>✅ Adaptación individual de learning rate por parámetro</p>
<p>✅ Funciona bien con gradientes ruidosos</p>
<p>✅ Requiere poca tunning manual</p>
</section>
<section id="walk-forward-validation">
<h3>Walk-Forward Validation<a class="headerlink" href="#walk-forward-validation" title="Link to this heading"></a></h3>
<p>Para predicciones de múltiples días, usamos un enfoque de <strong>rolling window</strong>:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>Día 1: Usar ventana [t-20:t] → Predecir t+1
Día 2: Usar ventana [t-19:t+1] → Predecir t+2
Día 3: Usar ventana [t-18:t+2] → Predecir t+3
...
</pre></div>
</div>
<p>Este método simula condiciones reales de trading.</p>
</section>
<section id="early-stopping">
<h3>Early Stopping<a class="headerlink" href="#early-stopping" title="Link to this heading"></a></h3>
<p>Implementamos Early Stopping para prevenir overfitting:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">EarlyStopping</span><span class="p">(</span>
    <span class="n">monitor</span><span class="o">=</span><span class="s1">&#39;val_loss&#39;</span><span class="p">,</span>    <span class="c1"># Vigilar pérdida en validación</span>
    <span class="n">patience</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span>           <span class="c1"># Esperar 15 epochs sin mejora</span>
    <span class="n">restore_best_weights</span><span class="o">=</span><span class="kc">True</span>  <span class="c1"># Regresar a mejor modelo</span>
<span class="p">)</span>
</pre></div>
</div>
<p>Si la pérdida en validación no mejora en 15 epochs consecutivos, el entrenamiento se detiene.</p>
<p>—</p>
</section>
</section>
<section id="preprocesamiento-de-datos">
<h2>Preprocesamiento de Datos<a class="headerlink" href="#preprocesamiento-de-datos" title="Link to this heading"></a></h2>
<section id="escalado-con-minmaxscaler">
<h3>Escalado con MinMaxScaler<a class="headerlink" href="#escalado-con-minmaxscaler" title="Link to this heading"></a></h3>
<p>Para la FFNN, escalamos los datos al rango [0, 1]:</p>
<div class="math notranslate nohighlight">
\[X_{scaled} = \frac{X - X_{min}}{X_{max} - X_{min}}\]</div>
<p><strong>Razones:</strong></p>
<ol class="arabic simple">
<li><p>Convergencia más rápida del optimizador</p></li>
<li><p>Evita dominancia de features con mayor magnitud</p></li>
<li><p>Previene problemas numéricos (overflow/underflow)</p></li>
</ol>
<p><strong>Importante:</strong> El scaler se ajusta SOLO con datos de entrenamiento para evitar data leakage.</p>
</section>
<section id="division-de-datos">
<h3>División de Datos<a class="headerlink" href="#division-de-datos" title="Link to this heading"></a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">Total</span> <span class="n">de</span> <span class="n">datos</span><span class="p">:</span> <span class="o">~</span><span class="mi">500</span> <span class="n">días</span> <span class="p">(</span><span class="mi">2</span> <span class="n">años</span><span class="p">)</span>

<span class="n">Train</span><span class="p">:</span> <span class="mi">470</span> <span class="n">días</span> <span class="p">(</span><span class="mi">94</span><span class="o">%</span><span class="p">)</span>
<span class="n">Test</span><span class="p">:</span>   <span class="mi">30</span> <span class="n">días</span> <span class="p">(</span><span class="mi">6</span><span class="o">%</span><span class="p">)</span>
<span class="n">Future</span><span class="p">:</span>  <span class="mi">5</span> <span class="n">días</span> <span class="p">(</span><span class="n">predicción</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Train Set:</strong> Para entrenar los modelos</p>
<p><strong>Test Set:</strong> Para evaluar performance antes de predicción final</p>
<p><strong>Future Set:</strong> Predicciones objetivo (20-24 octubre 2025)</p>
</section>
<section id="creacion-de-secuencias">
<h3>Creación de Secuencias<a class="headerlink" href="#creacion-de-secuencias" title="Link to this heading"></a></h3>
<p>Para la FFNN, transformamos datos de serie temporal en pares (X, y):</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Ejemplo con lookback=3</span>
<span class="n">Precios</span><span class="p">:</span> <span class="p">[</span><span class="mi">100</span><span class="p">,</span> <span class="mi">102</span><span class="p">,</span> <span class="mi">105</span><span class="p">,</span> <span class="mi">108</span><span class="p">,</span> <span class="mi">110</span><span class="p">,</span> <span class="mi">112</span><span class="p">]</span>

<span class="n">Secuencias</span><span class="p">:</span>
<span class="n">X</span><span class="o">=</span><span class="p">[</span><span class="mi">100</span><span class="p">,</span> <span class="mi">102</span><span class="p">,</span> <span class="mi">105</span><span class="p">]</span> <span class="err">→</span> <span class="n">y</span><span class="o">=</span><span class="mi">108</span>
<span class="n">X</span><span class="o">=</span><span class="p">[</span><span class="mi">102</span><span class="p">,</span> <span class="mi">105</span><span class="p">,</span> <span class="mi">108</span><span class="p">]</span> <span class="err">→</span> <span class="n">y</span><span class="o">=</span><span class="mi">110</span>
<span class="n">X</span><span class="o">=</span><span class="p">[</span><span class="mi">105</span><span class="p">,</span> <span class="mi">108</span><span class="p">,</span> <span class="mi">110</span><span class="p">]</span> <span class="err">→</span> <span class="n">y</span><span class="o">=</span><span class="mi">112</span>
</pre></div>
</div>
<p>Esto permite a la red aprender patrones históricos.</p>
<p>—</p>
</section>
</section>
<section id="metricas-de-evaluacion">
<h2>Métricas de Evaluación<a class="headerlink" href="#metricas-de-evaluacion" title="Link to this heading"></a></h2>
<p>Para comparar ambos modelos, usamos tres métricas estándar:</p>
<section id="rmse-root-mean-squared-error">
<h3>1. RMSE (Root Mean Squared Error)<a class="headerlink" href="#rmse-root-mean-squared-error" title="Link to this heading"></a></h3>
<div class="math notranslate nohighlight">
\[RMSE = \sqrt{\frac{1}{n}\sum_{i=1}^{n}(y_i - \hat{y}_i)^2}\]</div>
<ul class="simple">
<li><p><strong>Unidad</strong>: Misma que la variable (dólares)</p></li>
<li><p><strong>Interpretación</strong>: Error promedio en predicciones</p></li>
<li><p><strong>Sensible a outliers</strong>: Penaliza errores grandes</p></li>
</ul>
</section>
<section id="mae-mean-absolute-error">
<h3>2. MAE (Mean Absolute Error)<a class="headerlink" href="#mae-mean-absolute-error" title="Link to this heading"></a></h3>
<div class="math notranslate nohighlight">
\[MAE = \frac{1}{n}\sum_{i=1}^{n}|y_i - \hat{y}_i|\]</div>
<ul class="simple">
<li><p><strong>Unidad</strong>: Dólares</p></li>
<li><p><strong>Interpretación</strong>: Error absoluto promedio</p></li>
<li><p><strong>Más robusto</strong> a outliers que RMSE</p></li>
</ul>
</section>
<section id="mape-mean-absolute-percentage-error">
<h3>3. MAPE (Mean Absolute Percentage Error)<a class="headerlink" href="#mape-mean-absolute-percentage-error" title="Link to this heading"></a></h3>
<div class="math notranslate nohighlight">
\[MAPE = \frac{100}{n}\sum_{i=1}^{n}\left|\frac{y_i - \hat{y}_i}{y_i}\right|\]</div>
<ul class="simple">
<li><p><strong>Unidad</strong>: Porcentaje (%)</p></li>
<li><p><strong>Interpretación</strong>: Error relativo promedio</p></li>
<li><p><strong>Ventaja</strong>: Independiente de la escala del precio</p></li>
</ul>
</section>
<section id="criterios-de-exito">
<h3>Criterios de Éxito<a class="headerlink" href="#criterios-de-exito" title="Link to this heading"></a></h3>
<p>Un modelo se considera «bueno» si:</p>
<ul class="simple">
<li><p>✅ RMSE &lt; $10 (para acciones ~$100-500)</p></li>
<li><p>✅ MAE &lt; $7</p></li>
<li><p>✅ MAPE &lt; 5%</p></li>
<li><p>✅ Predicciones estables (sin saltos abruptos)</p></li>
</ul>
<p>—</p>
</section>
</section>
<section id="reproducibilidad">
<h2>Reproducibilidad<a class="headerlink" href="#reproducibilidad" title="Link to this heading"></a></h2>
<p>Para garantizar que los resultados sean reproducibles:</p>
<section id="semilla-fija">
<h3>Semilla Fija<a class="headerlink" href="#semilla-fija" title="Link to this heading"></a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">SEED</span> <span class="o">=</span> <span class="mi">42</span>

<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">SEED</span><span class="p">)</span>
<span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">set_seed</span><span class="p">(</span><span class="n">SEED</span><span class="p">)</span>
<span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">SEED</span><span class="p">)</span>
</pre></div>
</div>
<p>Esto asegura que:</p>
<ul class="simple">
<li><p>División train/test sea idéntica</p></li>
<li><p>Inicialización de pesos de FFNN sea consistente</p></li>
<li><p>Dropout y shuffle sean determinísticos</p></li>
</ul>
</section>
<section id="control-de-versiones">
<h3>Control de Versiones<a class="headerlink" href="#control-de-versiones" title="Link to this heading"></a></h3>
<p>Todas las dependencias tienen versiones fijas en <code class="docutils literal notranslate"><span class="pre">requirements.txt</span></code>:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>tensorflow==2.13.0
statsmodels==0.14.0
numpy==1.24.3
...
</pre></div>
</div>
</section>
<section id="entorno-de-ejecucion">
<h3>Entorno de Ejecución<a class="headerlink" href="#entorno-de-ejecucion" title="Link to this heading"></a></h3>
<ul class="simple">
<li><p><strong>Python</strong>: 3.8+</p></li>
<li><p><strong>Sistema</strong>: Compatible con Linux, macOS, Windows</p></li>
<li><p><strong>Hardware</strong>: CPU suficiente (GPU opcional para FFNN)</p></li>
</ul>
<p>—</p>
</section>
</section>
<section id="limitaciones-y-consideraciones">
<h2>Limitaciones y Consideraciones<a class="headerlink" href="#limitaciones-y-consideraciones" title="Link to this heading"></a></h2>
<section id="limitaciones-del-proyecto">
<h3>Limitaciones del Proyecto<a class="headerlink" href="#limitaciones-del-proyecto" title="Link to this heading"></a></h3>
<ol class="arabic simple">
<li><p><strong>Horizonte corto</strong>: Solo 5 días (dificultad aumenta exponencialmente)</p></li>
<li><p><strong>Datos históricos únicamente</strong>: No incorpora noticias o sentimiento</p></li>
<li><p><strong>Eventos imprevistos</strong>: No puede anticipar anuncios sorpresa</p></li>
<li><p><strong>Suposición de mercado eficiente</strong>: Los patrones del pasado pueden cambiar</p></li>
</ol>
</section>
<section id="supuestos-del-modelo">
<h3>Supuestos del Modelo<a class="headerlink" href="#supuestos-del-modelo" title="Link to this heading"></a></h3>
<ul class="simple">
<li><p>📊 Los datos históricos contienen información predictiva</p></li>
<li><p>📅 Los patrones temporales son relativamente estables</p></li>
<li><p>💹 No hay cambios estructurales drásticos durante predicción</p></li>
<li><p>🔄 Los mercados operan normalmente (no crisis inesperadas)</p></li>
</ul>
</section>
<section id="consideraciones-eticas">
<h3>Consideraciones Éticas<a class="headerlink" href="#consideraciones-eticas" title="Link to this heading"></a></h3>
<ul class="simple">
<li><p>⚠️ Este proyecto es <strong>académico</strong>, no constituye asesoría financiera</p></li>
<li><p>⚠️ No debe usarse para decisiones reales de inversión sin análisis adicional</p></li>
<li><p>⚠️ Los mercados financieros son inherentemente impredecibles</p></li>
</ul>
<p>—</p>
</section>
</section>
<section id="resumen-de-la-metodologia">
<h2>Resumen de la Metodología<a class="headerlink" href="#resumen-de-la-metodologia" title="Link to this heading"></a></h2>
<table class="docutils align-default">
<colgroup>
<col style="width: 25.0%" />
<col style="width: 35.0%" />
<col style="width: 40.0%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Aspecto</p></th>
<th class="head"><p>SARIMAX</p></th>
<th class="head"><p>FFNN</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><strong>Tipo de modelo</strong></p></td>
<td><p>Estadístico paramétrico</p></td>
<td><p>Aprendizaje profundo</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Hiperparámetros clave</strong></p></td>
<td><p>(p,d,q), (P,D,Q,s)</p></td>
<td><p>Capas, neuronas, dropout, LR</p></td>
</tr>
<tr class="row-even"><td><p><strong>Preprocesamiento</strong></p></td>
<td><p>Diferenciación</p></td>
<td><p>Escalado MinMax</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Ventajas</strong></p></td>
<td><p>Interpretable, teóricamente fundamentado</p></td>
<td><p>Captura no linealidades complejas</p></td>
</tr>
<tr class="row-even"><td><p><strong>Desventajas</strong></p></td>
<td><p>Asume linealidad, estacionariedad</p></td>
<td><p>Caja negra, requiere muchos datos</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Tiempo de entrenamiento</strong></p></td>
<td><p>Rápido (~segundos)</p></td>
<td><p>Moderado (~minutos)</p></td>
</tr>
</tbody>
</table>
<p>Ambos modelos son complementarios y su comparación permite evaluar si métodos estadísticos clásicos o deep learning son más efectivos para este problema específico.</p>
</section>
</section>


           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Derechos de autor 2024, Tu Equipo.</p>
  </div>

  Compilado con <a href="https://www.sphinx-doc.org/">Sphinx</a> usando un
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">tema</a>
    proporcionado por <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>